{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rhodes-byu/cs-stat-180/blob/main/notebooks/03a-pandas-intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2yFa9qJDOSe"
   },
   "source": [
    "# Pandas\n",
    "\n",
    "The pandas module is one of the most powerful tools for data analysis.  Pandas was designed to work with tabular and heterogeneous data.  The original author of pandas is Wes McKinney, so it makes sense that most of his book \"Python for Data Analysis\" covers the functionality of pandas. In fact, chapters 5 - 11 are basically about what pandas can do.  \n",
    "\n",
    "Here are some of the things that I hope you can do by the end of the section:\n",
    "* Create Series and DataFrames (ch 5)\n",
    "* Index, slice, and filter (ch 5)\n",
    "* Examine your data (ch 5)\n",
    "* Compute summarization and descriptive statistics (ch 5)\n",
    "* Drop rows and columns (ch 5)\n",
    "* Create columns (ch 5)\n",
    "* Count the number of missing values (ch 7)\n",
    "* Drop or fill missing values (ch 7)\n",
    "* Drop duplicate rows (ch 7)\n",
    "* Combine categories of categorical data (ch 7)\n",
    "* Discretize numerical data (ch 7)\n",
    "* Have some practice with hierarchical indexing (ch 8)\n",
    "* Reset the index (ch 8)\n",
    "* Merge and concatenate DataFrames (ch 8)\n",
    "* Simple plots with pandas (ch 9)\n",
    "* Use .groupby() for category aggregation (ch 10)\n",
    "* Fill missing values by group summary statistics (ch 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju1RU9WWDOSh"
   },
   "source": [
    "## Importing Pandas\n",
    "\n",
    "It is standard to use the alias ``pd`` when importing pandas.\n",
    "~~~\n",
    "import pandas as pd\n",
    "~~~\n",
    "I usually import numpy at the same time since pandas and numpy are often used in tandem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyYhJfptDOSh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you can install pandas within the notebook:\n",
    "# !pip install pandas\n",
    "# OR\n",
    "# !conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mokmfDpDDOSi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Try:  Create a Series from a list\n",
    "x = [1,2,3,4,5]\n",
    "lab = ['a','b','c','d','e']\n",
    "\n",
    "s = pd.Series(x, index=lab)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MH-mNGXbDOSi"
   },
   "outputs": [],
   "source": [
    "# Creating a Series with a dictionary\n",
    "\n",
    "d = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pA-jXpPuDOSj"
   },
   "source": [
    "## DataFrames\n",
    "DataFrames are the main data structure of pandas and were directly inspired by the R programming language.  DataFrames are a bunch of Series objects put together to share the same (row) index.  A DataFrame has both a row and a column index.  \n",
    "\n",
    "## Creating DataFrames\n",
    "DataFrames can also be created from lists, dictionaries, or numpy arrays.\n",
    "Syntax: pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1286pWSDOSj"
   },
   "outputs": [],
   "source": [
    "x = [[1, 2, 3],\n",
    "     ['a', 'b', 'c'],\n",
    "     [4, 5, 6]]\n",
    "\n",
    "x_df = pd.DataFrame(x, columns = ['p', 'd', 'q'], index = ['x', 'y', 'z'])\n",
    "print(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQca_SbjDOSj"
   },
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'Salary': [50000, 60000, 75000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IhxW6qgDOSj"
   },
   "outputs": [],
   "source": [
    "# Accessing specific columns\n",
    "names = df['Name']\n",
    "ages = df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ud41ppC1DOSk"
   },
   "outputs": [],
   "source": [
    "print(\"Names: \\n\", names)\n",
    "print(\"Ages: \\n\", ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVDs2FswDOSk"
   },
   "outputs": [],
   "source": [
    "# Add a new column calculated from existing columns\n",
    "df['Birth Year'] = 2023 - df['Age']\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4arP7HjJDOSk"
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by Age in descending order\n",
    "df_sorted = df.sort_values(by='Birth Year', ascending=True) # Note: Sorting can also be done in-place with inplace=True\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kigOHSSDOSk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcVzcAlpDOSk"
   },
   "source": [
    "## Read in some practice data\n",
    "\n",
    "pd.read_csv can be used to load in external .csv files  \n",
    "We can access a summary of the data using df.info()  \n",
    "We can use df.head() to view the first view entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuLGuAZSDOSk"
   },
   "outputs": [],
   "source": [
    "# Iris data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "iris = pd.read_csv(url, names=['sepal_length','sepal_width', 'petal_length', 'petal_width', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4aDYI6hDOSk"
   },
   "source": [
    "## Looking at your DataFrame\n",
    "\n",
    "``df.head()``  \n",
    "``df.tail()``  \n",
    "``df.shape``  \n",
    "``df.info()``  \n",
    "``df.describe()``   \n",
    "``df.columns``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVPhPTQxDOSk"
   },
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6aRueORDOSl"
   },
   "outputs": [],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKRHqQ61DOSl"
   },
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZ5TfVZxDOSl"
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "iris.rename(columns={'class': 'species'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame with renamed columns\n",
    "iris.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQy9e7zCDOSl"
   },
   "source": [
    "## Basic Plotting\n",
    "Pandas can be used for basic plotting, but we will cover more later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRwEBbLbDOSl"
   },
   "outputs": [],
   "source": [
    "iris['sepal_length'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eE7FvE9HDOSl"
   },
   "outputs": [],
   "source": [
    "iris.plot.scatter('sepal_length','sepal_width', c='petal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSs6XgaoDOSl"
   },
   "outputs": [],
   "source": [
    "iris.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bxf2Bh-UDOSl"
   },
   "outputs": [],
   "source": [
    "iris.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4yFi_7DDOSl"
   },
   "source": [
    "---\n",
    "\n",
    "## Selection and Indexing\n",
    "\n",
    "There are various ways to get subsets of the data.  In the following ``df`` refers to a DataFrame.\n",
    "\n",
    "#### Selecting columns\n",
    "One column (producing a Series)\n",
    "~~~\n",
    "df['column_name']  # Prefered method\n",
    "df.column_name \n",
    "~~~\n",
    "---\n",
    "\n",
    "Multiple columns (producing a DataFrame)\n",
    "~~~\n",
    "df[['column_name']] # this will produce a DataFrame\n",
    "df[['col1', 'col2', 'col3']]\n",
    "~~~\n",
    "---\n",
    "\n",
    "#### Selecting row and columns with ``loc`` and ``iloc``\n",
    "~~~\n",
    "df.loc['row_name', 'col_name'] \n",
    "df.iloc['row index', 'col index']\n",
    "~~~\n",
    "\n",
    "``loc`` and ``iloc`` also support slicing.  Note: when slicing with ``loc``, the end point IS including (but not when slicing with ``iloc``.\n",
    "\n",
    "---\n",
    "~~~\n",
    "df.loc['row_name1':'row_name2', 'col_name1':'col_name2']\n",
    "df.loc[:, 'col_name1':'col_name2']\n",
    "df.loc['r1':'r2', :]\n",
    "df.loc[['r1','r2','r3'],['c1','c2]]\n",
    "~~~\n",
    "*When using `.loc()`, `row_name2` and `col_name2` WILL be included*\n",
    "\n",
    "---\n",
    "~~~\n",
    "df.iloc[index1:index2, col1:col2]\n",
    "~~~\n",
    "*When using `.iloc()`, `index2` and `col2` will NOT be included*\n",
    "\n",
    "---\n",
    "#### Selecting rows based on column condition\n",
    "~~~\n",
    "df[df[boolean condition]]\n",
    "\n",
    "df[mask]\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kt64D6uJDOSl"
   },
   "outputs": [],
   "source": [
    "iris.loc[0:5, ['petal_width', 'petal_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLXIabquDOSl"
   },
   "outputs": [],
   "source": [
    "iris.iloc[0:2, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZJ65SgDDOSl"
   },
   "outputs": [],
   "source": [
    "iris['sepal_length'] > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po_be23cDOSl"
   },
   "outputs": [],
   "source": [
    "## Slicing with a boolean series\n",
    "iris[iris['sepal_length'] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBwr3oqdDOSl"
   },
   "outputs": [],
   "source": [
    "# Filter data using multiple conditions (Note the parentheses!)\n",
    "filtered_iris = iris[(iris['sepal_length'] > 6) & (iris['petal_length'] > 5)]\n",
    "filtered_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyaP7UG_DOSl"
   },
   "outputs": [],
   "source": [
    "# Reset to default 0,1...n index\n",
    "filtered_iris.reset_index(drop = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Fj2UddtHN3X"
   },
   "source": [
    "## Multi-Index and Index Hierarchy\n",
    "\n",
    "Let us go over how to work with Multi-Index, first we'll create a quick example of what a Multi-Indexed DataFrame would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrNrvRq3HcTw"
   },
   "outputs": [],
   "source": [
    "# Index Levels\n",
    "outside = ['G1','G1','G1','G2','G2','G2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqmaCVtMHeSj"
   },
   "outputs": [],
   "source": [
    "hier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Mh7fEZyHe8D"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,2),index=hier_index,columns=['A','B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaV88xiaHfhS"
   },
   "source": [
    "Now let's show how to index this! For index hierarchy we use df.loc[], if this was on the columns axis, you would just use normal bracket notation df[]. Calling one level of the index returns the sub-dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_7vEfmlHpdI"
   },
   "outputs": [],
   "source": [
    "df.loc['G1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0NfjoBWHpVs"
   },
   "outputs": [],
   "source": [
    "df.loc['G1'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x72aaouHpLk"
   },
   "outputs": [],
   "source": [
    "df.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjAgJuq4HpAR"
   },
   "outputs": [],
   "source": [
    "df.index.names = ['Group','Num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juONH7waHozu"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UllmZaVrHf2a"
   },
   "outputs": [],
   "source": [
    "# The xs() method in pandas is used to extract a cross-section from a DataFrame or Series\n",
    "df.xs('G1', level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs(1, level = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs(1, level = 1).reset_index()\n",
    "# df.xs(1, level = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDR3GkehDOSl"
   },
   "source": [
    "## Methods for computing summary and descriptive statistics\n",
    "pandas objects have many reduction / summary statistics methods that extract a single value from the rows or columms of a DataFrame.  See Table 5-8 in *Python for Data Analysis* for a more complete list, but here are a few that are commonly used.\n",
    "\n",
    "`count`: number of non-NA values   \n",
    "`describe`: summary statistics for numerical columns   \n",
    "`min`, `max`: min and max values  \n",
    "`argmin`, `argmax`: index of min and max values (for Series only)   \n",
    "`idxmin`, `idxmax`: index or column name of min and max values  \n",
    "`sum`: sum of values  \n",
    "`cumsum` : cummulative sum\n",
    "`mean`: mean of values  \n",
    "`quantile`: quantile from 0 to 1 of values  \n",
    "`var`: (sample) variance of values  \n",
    "`std`: (sample) standard deviation of values  \n",
    "`df.corr()` and `df.cov()` will produce the correlation or covariance matrix.  Or two Series can be used to get the correlation (or covariance) with `Series1`.corr(`Series2`).\n",
    "\n",
    "Numpy functions can also be used: `np.corrcoef()`\n",
    "\n",
    "Most of these functions also take an `axis` argument which specifies whether to reduce over rows or columns: 0 for rows and 1 for columns.   \n",
    "There is also an argument `skipna` which specifies whether or not to skip missing values.  The default is True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84wB2FoeDOSl"
   },
   "outputs": [],
   "source": [
    "iris.sepal_length.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y99_yvm5DOSp"
   },
   "outputs": [],
   "source": [
    "iris.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUMM3yHoDOSp"
   },
   "source": [
    "## Unique values and value counts\n",
    "\n",
    "``df.nunique()`` or ``df['column'].nunique()``  \n",
    "\n",
    "``df.value_counts()`` or ``df['column'].value_counts()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUTcSnT6DOSp"
   },
   "outputs": [],
   "source": [
    "iris.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4xbl1-ODOSp"
   },
   "outputs": [],
   "source": [
    "iris.species.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESR4rkimDOSp"
   },
   "source": [
    "`df.corr()` and `df.cov()` will produce the correlation or covariance matrix.  Or two Series can be used to get the correlation (or covariance) with `Series1`.corr(`Series2`).\n",
    "\n",
    "Numpy functions can also be used: `np.corrcoef()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roEKPoRSDOSp"
   },
   "outputs": [],
   "source": [
    "iris.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsur0pX4DOSp"
   },
   "source": [
    "---\n",
    "## Dropping rows and columns\n",
    "\n",
    "Columns and rows can be dropped with the `.drop()` method (using `axis=1` for columns and `axis=0` (default) for rows).  This method creates a new object unless `.inplace = True` is specified.\n",
    "\n",
    "The `del` command can also be used to drop columns in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAK4DgoUDOSp"
   },
   "outputs": [],
   "source": [
    "no_species = iris.drop('species', axis = 1)\n",
    "no_species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHMeU8FJDOSp"
   },
   "outputs": [],
   "source": [
    "# The original is unchanged if inplace = False\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qsRj2gRDOSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0pjnWMmDOSp"
   },
   "source": [
    "## Adding columns\n",
    "\n",
    "Add a new column to the end of a data frame\n",
    "~~~\n",
    "df['new_col'] = value\n",
    "~~~\n",
    "\n",
    "Add a new column at a specific index\n",
    "\n",
    "`.insert(col_index, 'new_col_name', value(s))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUvFmVgaDOSp"
   },
   "outputs": [],
   "source": [
    "iris['sum_petal_dims'] = iris['petal_length'] + iris['petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tL1lm4BoDOSp"
   },
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j70DQ1UeDOSq"
   },
   "source": [
    "## Missing Values\n",
    "\n",
    "**Ways to count missing values**\n",
    "~~~\n",
    "df.info()\n",
    "df.isna().sum()\n",
    "df.isna().sum(axis=0)\n",
    "~~~\n",
    "\n",
    "**Drop missing values with `.dropna()`**\n",
    "\n",
    "Calling `.dropna()` without any arguments will drop all rows with missing values\n",
    "\n",
    "Arguments:\n",
    "* `axis=1` will drop columns with missing values (default is `axis=0`)\n",
    "* `how='all'` will drop rows (or columns) if all the values are NA (default is `how='any'`)\n",
    "* `subset=` will limit na search to these specic columns (or indexes)\n",
    "    \n",
    "\n",
    "**Fill missing values with `.fillna()`**\n",
    "Arguments:\n",
    "* `value`: value used to fill.\n",
    "* `method'`: methods used to fill (forward or backward fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITwS7RGkDOSq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtJJpcCzDOSq"
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame with missing values\n",
    "missing_data = {'A': [1, 2, np.nan],\n",
    "        'B': [np.nan, 4, 6],\n",
    "        'C': [7, 8, 9]}\n",
    "\n",
    "m_df = pd.DataFrame(missing_data)\n",
    "m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHY4b6NHDOSq"
   },
   "outputs": [],
   "source": [
    "m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GU9Q9kgyDOSq"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "m_df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCyT7G1ZDOSq"
   },
   "outputs": [],
   "source": [
    "# Check how many missing values\n",
    "m_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v27TzUpgDOSq"
   },
   "outputs": [],
   "source": [
    "# Check how many missing values\n",
    "m_df.isna().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HCStCbgDOSq"
   },
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "df_filled = m_df.fillna(-1)\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIGcsTZsDOSr"
   },
   "outputs": [],
   "source": [
    "m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eankcnysDOSr"
   },
   "outputs": [],
   "source": [
    "# Fill with mean column value\n",
    "m_df.fillna(m_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F79glDWIDOSr"
   },
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df_dropped = m_df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fk6R9FHnDOSr"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKPVYsqdJ9tA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CylNK4RKJ9tA"
   },
   "outputs": [],
   "source": [
    "# Make the data directory if it doesn't exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to a CSV file\n",
    "df.to_csv('data/data.csv', index=False)\n",
    "\n",
    "# Read data from a CSV file\n",
    "new_df = pd.read_csv('data/data.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSAQVNW-J9tB"
   },
   "source": [
    "### Read in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7krctQi6J9tB"
   },
   "outputs": [],
   "source": [
    "# Downloading data to data/ directory (May not work on Windows)\n",
    "!curl -L -o data/example_csv.csv https://raw.githubusercontent.com/rhodes-byu/stat386-datasets/refs/heads/main/reading_examples/example_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdhbVSZGJ9tB"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/example_csv.csv', index_col = 0, thousands = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rro4u6oPJ9tB"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtVGxKvVJ9tB"
   },
   "source": [
    "## read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JqXvBWCJ9tC"
   },
   "outputs": [],
   "source": [
    "!curl -L -o data/example_excel.xlsx https://raw.githubusercontent.com/rhodes-byu/stat386-datasets/refs/heads/main/reading_examples/example_excel.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZAwv_SWJ9tC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/example_excel.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kb9zOBXqJ9tC"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJGlus8sJ9tC"
   },
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaVmkQrDJ9tC"
   },
   "outputs": [],
   "source": [
    "lines = df['lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-2gpvyKJ9tC"
   },
   "outputs": [],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kd8a1iqKJ9tC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/example_excel.xlsx', sheet_name = 'lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mto-J9-xJ9tC"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSbf52uAJ9tC"
   },
   "source": [
    "## json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VpRqf0SJ9tC"
   },
   "outputs": [],
   "source": [
    "!curl -L -o data/example_json.json https://raw.githubusercontent.com/rhodes-byu/stat386-datasets/refs/heads/main/reading_examples/example_json.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md9d8S3JJ9tC"
   },
   "outputs": [],
   "source": [
    "pd.read_json('data/example_json.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzytMS8TJ9tC"
   },
   "outputs": [],
   "source": [
    "with open('data/example_json.json', 'r') as file:\n",
    "    json_object = json.load(open('data/example_json.json', 'r'))\n",
    "\n",
    "print(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCehVkh-J9tD"
   },
   "outputs": [],
   "source": [
    "json_object['cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMq4T45KJ9tD"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuJNsM8wJ9tD"
   },
   "outputs": [],
   "source": [
    "pd.json_normalize(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYnnG1I3J9tD"
   },
   "source": [
    "## read_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yd25hAu0J9tD"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Super_Bowl_champions\"\n",
    "\n",
    "# Set a user-agent header\n",
    "headers = {'User-Agent': 'Personal'}\n",
    "\n",
    "# Fetch page content with user-agent\n",
    "html = requests.get(url, headers=headers).content\n",
    "\n",
    "# Parse all tables\n",
    "dfs = pd.read_html(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3cjXcOPJ9tD"
   },
   "outputs": [],
   "source": [
    "# Reads in a list of DataFrames from the URL (based on tables)\n",
    "dfs = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrcgXcaFJ9tD"
   },
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrJPkoIwJ9tD"
   },
   "outputs": [],
   "source": [
    "dfs[9].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-ZuchSIJ9tD"
   },
   "outputs": [],
   "source": [
    "pd.read_html(url, match = 'Joe Robbie')[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K4aDYI6hDOSk",
    "WQy9e7zCDOSl",
    "rDR3GkehDOSl"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
